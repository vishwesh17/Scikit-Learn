{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Scikit-Learn (sklearn)\n",
    "This notebook demonstrates some of the most useful functions of the beautiful Scikit-Learn library.\n",
    "\n",
    "\n",
    "0. An end-to-end Scikit-Learn workflow,\n",
    "1. Getting the data ready\n",
    "2. Choose the right estimator/algorithm for our problems\n",
    "3. Fit the model/algorithm and use it to make predictions on our data\n",
    "4. Evaluating a model\n",
    "5. Improve a model\n",
    "6. Save and load a trained model\n",
    "7. Putting it all together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's listify the contents\n",
    "what_were_covering = [\n",
    "    \"0. An end-to-end Scikit-Learn workflow\",\n",
    "    \"1. Getting the data ready\",\n",
    "    \"2. Choose the right estimator/algorithm for our problems\",\n",
    "    \"3. Fit the model/algorithm and use it to make predictions on our data\",\n",
    "    \"4. Evaluating a model\",\n",
    "    \"5. Improve a model\",\n",
    "    \"6. Save and load a trained model\",\n",
    "    \"7. Putting it all together!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. An end-to-end Scikit-Learn workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. getting data ready\n",
    "import pandas as pd\n",
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X (feature matrix)\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "\n",
    "# create y (labels)\n",
    "y = heart_disease[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    1\n",
       " 1    1\n",
       " 2    1\n",
       " 3    1\n",
       " 4    1\n",
       " Name: target, dtype: int64, 1    165\n",
       " 0    138\n",
       " Name: target, dtype: int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(), y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. choose the right model and hyperparameters (hyperparameters are like dials on a model that you can tune to\n",
    "# make it better or worst) #  Choose the right estimator/algorithm for our problems\n",
    "# Random Forest Classifier (for classification problems)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "# clf = classifier/model\n",
    "\n",
    "# we will keep the default hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. fit the model to training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "# 0.2 means 80% of the data would be used for trainng 20% testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>227</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>213</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>212</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>288</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>135</td>\n",
       "      <td>304</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "152   64    1   3       170   227    0        0      155      0      0.6   \n",
       "34    51    1   3       125   213    0        0      125      1      1.4   \n",
       "215   43    0   0       132   341    1        0      136      1      3.0   \n",
       "275   52    1   0       125   212    0        1      168      0      1.0   \n",
       "59    57    0   0       128   303    0        0      159      0      0.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "223   56    0   0       200   288    1        0      133      1      4.0   \n",
       "197   67    1   0       125   254    1        1      163      0      0.2   \n",
       "96    62    0   0       140   394    0        0      157      0      1.2   \n",
       "272   67    1   0       120   237    0        1       71      0      1.0   \n",
       "36    54    0   2       135   304    1        1      170      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "152      1   0     3  \n",
       "34       2   1     2  \n",
       "215      1   0     3  \n",
       "275      2   2     3  \n",
       "59       2   1     2  \n",
       "..     ...  ..   ...  \n",
       "223      0   2     3  \n",
       "197      1   2     3  \n",
       "96       1   0     2  \n",
       "272      1   0     2  \n",
       "36       2   0     2  \n",
       "\n",
       "[242 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286    0\n",
       "133    1\n",
       "248    0\n",
       "92     1\n",
       "43     1\n",
       "      ..\n",
       "287    0\n",
       "95     1\n",
       "283    0\n",
       "285    0\n",
       "241    0\n",
       "Name: target, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2fe890b282ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this doesnt work...incorrect shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[0. 2. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "# this doesnt work...incorrect shape\n",
    "y_label = clf.predict(np.array([0,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model to make prediction\n",
    "# The whole point of training a machine learning model is to use it to make some kind of prediction in the future.\n",
    "\n",
    "# Once our model instance is trained, you can use the predict() method to predict a target value given \n",
    "# a set of features. In other words, use the model, along with some unlabelled data to predict the label.\n",
    "\n",
    "# Note, data you predict on has to be in the same shape as data you trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to predict a label, data has to be in the same shape as X_train\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = clf.predict(X_test)\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 evaluating the model of train and test data\n",
    "\n",
    "# Now we've made some predictions, we can start to use some more Scikit-Learn methods to figure out how good\n",
    "# our model is.\n",
    "# Each model or estimator has a built-in score method. This method compares how well the model was able to\n",
    "# learn the patterns between the features and labels. In other words, it returns how accurate your model is.\n",
    "\n",
    "clf.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more classification metrics we can use other then accuracy:\n",
    "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
    "\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. improve a model\n",
    "# try different amount of n_estimators\n",
    "np.random.seed(42)\n",
    "for i in range(10,100,10):\n",
    "    print(f\"Tying model with {i} estimators..\")\n",
    "    clf = RandomForestClassifier(n_estimators=i).fit(X_train,y_train)\n",
    "    print(f\"Model accuracy on tet set: {clf.score(X_test,y_test)*100:2f}%\")\n",
    "    print(\"\")                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. save a model and load\n",
    "import pickle\n",
    "\n",
    "#save a existing model to a file\n",
    "pickle.dump(clf, open(\"random_forst_model_1.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a saved model and make a prediction\n",
    "loaded_model = pickle.load(open(\"random_forst_model_1.pkl\", \"rb\"))\n",
    "loaded_model.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting our data ready to be used with machine learning\n",
    "Three main things we have to do:\n",
    "\n",
    "1. Split the data into features and labels (usually `X` & `y`)\n",
    "2. Filling (also called imputing) or disregarding missing values\n",
    "3. Converting non-numerical values to numerical values (also called feature encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_disease.drop(\"target\",axis =1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = heart_disease[\"target\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So in machine learning one of the most fundamental principles is never evaluate or test your models\n",
    "# on data that it is learned from.\n",
    "# Which is why we split it into training and test sets so scikit learn has a convenient function for allowing\n",
    "# us to do that.\n",
    "# So split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into training and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train, X_test, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 242 rows and 13 features(columns) 80% of training data\n",
    "# 61 rows and 13 features(column) 20 % of test data\n",
    "# 242 rows from 'target' column is 80% training data\n",
    "# 61 rows from 'target' column is 20% test data\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X.shape[0] * 0.8)\n",
    "print(242+61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 make sure its all numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales = pd.read_csv(\"car-sales-extended.csv\")\n",
    "car_sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X to predict y\n",
    "# splitting into X/y\n",
    "X = car_sales.drop(\"Price\", axis = 1)\n",
    "y = car_sales[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(),y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting into training and split\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 800 rows and 4 features(columns) 80% of training data \n",
    "# 200 rows and 4 features(column) 20 % of test data \n",
    "# 800 rows from 'price' column is 80% training data \n",
    "# 200 rows from 'price' column is 20% test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(X.shape[0] * 0.8)\n",
    "print(800+200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# create + train + run in,evaluate in 4 lines of code\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# We want to train it on the training data so it's going to learn the patterns the relationships between\n",
    "# X variables and the price the label.\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# we're gonna score it evaluated on the test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oops... this doesn't work, we'll have to convert it to numbers first.(previous cell giving error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the categories (Make and Colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "One_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"One_hot\", One_hot, categorical_features)],remainder = \"passthrough\")\n",
    "                                 \n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting it in dataframe\n",
    "pd.DataFrame(transformed_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd alternative #Turn the categories (Make and Colour) into numbers\n",
    "# \"Doors\" are numerical so it didnt work over here but it worked in 1st methood\n",
    "dummies = pd.get_dummies(car_sales[[\"Make\", \"Colour\", \"Doors\"]])\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's refit the model. taking \"y\" as didnt changed anything in previous cells\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X, y, test_size=0.2)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 what if there are missing values?\n",
    "1. fill them with values(also known as imputation)\n",
    "2. Remove the samples with missing data all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Many machine learning models don't work well when there are missing values in the data.\n",
    "\n",
    "# There are two main options when dealing with missing values.\n",
    "\n",
    "# Fill them with some given value. For example, you might fill missing values of a numerical column with the mean of all the other values. The practice of filling missing values is often referred to as imputation.\n",
    "# Remove them. If a row has missing values, you may opt to remove them completely from your sample completely. However, this potentially results in using less data to build your model.\n",
    "# Note: Dealing with missing values is a problem to problem issue. And there's often no best way to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import car sales missing data\n",
    "car_sales_missing = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many data is missing\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis = 1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the categorical columns to one hot encoded (code copied from above)\n",
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories(make, colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(X)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahh... this doesn't work. We'll have to either fill or remove the missing values.\n",
    "\n",
    "# Let's see what values are missing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_missing[\"Doors\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 Fill missing data with pandas (option 1)\n",
    "What we'll do is fill the rows where categorical values are missing with \"missing\", the numerical features with the mean or 4 for the doors. And drop the rows where the Price is missing.\n",
    "\n",
    "We could fill Price with the mean, however, since it's the target variable, we don't want to be introducing too many fake labels.\n",
    "\n",
    "Note: The practice of filling missing data is called imputation. And it's important to remember there's no perfect way to fill missing data. The methods we're using are only one of many. The techniques you use will depend heavily on your dataset. A good place to look would be searching for \"data imputation techniques\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill the 'make' column\n",
    "car_sales_missing[\"Make\"].fillna(\"missing\", inplace = True)\n",
    "\n",
    "# fill the 'colour' column\n",
    "car_sales_missing[\"Colour\"].fillna(\"missing\", inplace = True)\n",
    "\n",
    "# fill the 'Odometer (KM)' column with mean\n",
    "car_sales_missing[\"Odometer (KM)\"].fillna(car_sales_missing[\"Odometer (KM)\"].mean(), inplace = True)\n",
    "\n",
    "# # fill the 'Doors' column with 4\n",
    "car_sales_missing[\"Doors\"].fillna(4, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check our dataframe again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing row with missing price value/labels\n",
    "car_sales_missing.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data frame again\n",
    "car_sales_missing.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_missing)\n",
    "# we lost 50 rows from 1000 rows = 950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-create X and y\n",
    "X = car_sales_missing.drop(\"Price\", axis = 1)\n",
    "y = car_sales_missing[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the categorical columns to one hot encoded (code copied from above)\n",
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories(make, colour) into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_missing) # if we put just\"x\" as above it will not show numbers\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 Fill missing data with Scikit-Learn (option 2)\n",
    "Now we've filled the missing columns using pandas functions, you might be thinking, \"Why pandas? I thought this was a Scikit-Learn introduction?\".\n",
    "\n",
    "Not to worry, scikit-learn provides another method called SimpleImputer() which allows us to do a similar thing.\n",
    "\n",
    "SimpleImputer() transforms data by filling missing values with a given strategy.\n",
    "\n",
    "And we can use it to fill the missing values in our DataFrame as above.\n",
    "\n",
    "At the moment, our dataframe has no mising values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing again as we have filled all missing values in above cells. (using \"mising\" and in above used \"missing\")\n",
    "car_sales_mising = pd.read_csv(\"car-sales-extended-missing-data.csv\")\n",
    "car_sales_mising.head()\n",
    "#print(len(car_sales_missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_mising.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing in the \"Price\" column(no labels)\n",
    "car_sales_mising.dropna(subset=[\"Price\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_mising.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well we want to split into x and y.\n",
    "# Plenty of practice doing this this is what a lot of lot of machine learning problems end up being right\n",
    "# is it's turning your data into features and labels and then getting a machine learning model to hopefully\n",
    "# learn some patterns in those features and predict labels.\n",
    "# That's what we're going to try and do here.\n",
    "# Access equals one beautiful why we've seen this before.\n",
    "# Car sales missing price.\n",
    "# So again we're just using these four columns here to predict the price column.\n",
    "X = car_sales_mising.drop(\"Price\", axis=1)\n",
    "y = car_sales_mising[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().sum()\n",
    "#y.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values with scikit-learn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# fill categorical values with 'missing' and numerical values with mean\n",
    "cat_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
    "door_imputer = SimpleImputer(strategy='constant', fill_value = 4)\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Define columns\n",
    "cat_features = [\"Make\", \"Colour\"]\n",
    "door_feature = [\"Doors\"]\n",
    "num_features = [\"Odometer (KM)\"]\n",
    "\n",
    "# create an imputer (something that fills missing data)\n",
    "imputer = ColumnTransformer([\n",
    "    ('cat_imputer', cat_imputer, cat_features),\n",
    "    ('door_imputer',door_imputer, door_feature),\n",
    "    ('num_imputer', num_imputer, num_features)\n",
    "])\n",
    "\n",
    "# Transform the data\n",
    "filled_X = imputer.fit_transform(X)\n",
    "filled_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled = pd.DataFrame(filled_X,\n",
    "                               columns=[\"Make\", \"Colour\", \"Doors\", \"Odometer (KM)\"])\n",
    "car_sales_filled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_sales_filled.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try and convert our data to numbers\n",
    "# Turn the categories into numbers\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "categorical_features = [\"Make\", \"Colour\", \"Doors\"]\n",
    "one_hot = OneHotEncoder()\n",
    "transformer = ColumnTransformer([(\"one_hot\",\n",
    "                                   one_hot,\n",
    "                                   categorical_features)],\n",
    "                                   remainder=\"passthrough\")\n",
    "\n",
    "transformed_X = transformer.fit_transform(car_sales_filled)\n",
    "transformed_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've got our data as numbers and filled (no missing values)\n",
    "# Let's fit a model\n",
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,y,test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### using n_estimator=100\n",
    "# Now we've got our data as numbers and filled (no missing values)\n",
    "# Let's fit a model\n",
    "# Now we've transformed X, let's see if we can fit a model\n",
    "np.random.seed(42)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(transformed_X,y,test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(car_sales_filled), len(car_sales), len(car_sales_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the key takeaways to remember are:\n",
    "\n",
    "1.Most datasets you come across won't be in a form ready to immediately start using them with machine learning models. And some may take more preparation than others to get ready to use.\n",
    "2.For most machine learning models, your data has to be numerical. This will involve converting whatever you're working with into numbers. This process is often referred to as feature engineering or feature encoding.\n",
    "3.Some machine learning models aren't compatible with missing data. The process of filling missing data is referred to as data imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so the process of filling missing values is called imputation and the process of turning your non\n",
    "\n",
    "#numerical values into numerical values is referred to as feature engineering or feature encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Choosing the right estimator/algorithm for our problemÂ¶\n",
    "**Scikit-Learn uses estimator as another term for machine learning model or algorithm.**\n",
    "\n",
    "* Classification - predicting whether a sample is one thing or another\n",
    "* Regression - predicting a number\n",
    "\n",
    "step 1: Check the Scikit-Learn machine learning map.... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "**Some things to note:**\n",
    "\n",
    "* Sklearn refers to machine learning models and algorithms as estimators.\n",
    "* Classification problem - predicting a category (heart disease or not).\n",
    "* Sometimes you'll see clf (short for classifier) used as a classification estimator instance's variable name.\n",
    "* Regression problem - predicting a number (selling price of a car).\n",
    "* Unsupervised problem - clustering (grouping unlabelled samples with other similar unlabelled samples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Picking a machine learning model for a regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing boston hoousing data set\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "boston; # imports as dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it's in a dictionary, let's turn it into a DataFrame so we can inspect it better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df = pd.DataFrame(boston[\"data\"], columns = boston[\"feature_names\"])\n",
    "boston_df[\"target\"] = pd.Series(boston[\"target\"])\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many samples\n",
    "len(boston_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       0\n",
       "ZN         0\n",
       "INDUS      0\n",
       "CHAS       0\n",
       "NOX        0\n",
       "RM         0\n",
       "AGE        0\n",
       "DIS        0\n",
       "RAD        0\n",
       "TAX        0\n",
       "PTRATIO    0\n",
       "B          0\n",
       "LSTAT      0\n",
       "target     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.isna().sum()\n",
    "# no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM     ZN  INDUS   CHAS    NOX     RM    AGE    DIS    RAD    TAX  \\\n",
       "0    False  False  False  False  False  False  False  False  False  False   \n",
       "1    False  False  False  False  False  False  False  False  False  False   \n",
       "2    False  False  False  False  False  False  False  False  False  False   \n",
       "3    False  False  False  False  False  False  False  False  False  False   \n",
       "4    False  False  False  False  False  False  False  False  False  False   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "501  False  False  False  False  False  False  False  False  False  False   \n",
       "502  False  False  False  False  False  False  False  False  False  False   \n",
       "503  False  False  False  False  False  False  False  False  False  False   \n",
       "504  False  False  False  False  False  False  False  False  False  False   \n",
       "505  False  False  False  False  False  False  False  False  False  False   \n",
       "\n",
       "     PTRATIO      B  LSTAT  target  \n",
       "0      False  False  False   False  \n",
       "1      False  False  False   False  \n",
       "2      False  False  False   False  \n",
       "3      False  False  False   False  \n",
       "4      False  False  False   False  \n",
       "..       ...    ...    ...     ...  \n",
       "501    False  False  False   False  \n",
       "502    False  False  False   False  \n",
       "503    False  False  False   False  \n",
       "504    False  False  False   False  \n",
       "505    False  False  False   False  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, our goal here is to use the feature columns, such as CRIM, which is the per capita crime rate by town, AGE, the proportion of owner-occupied units built prior to 1940 and more to predict the target column. Where the target column is the median house prices.\n",
    "\n",
    "In essence, each row is a different town in Boston (the data) and we're trying to build a model to predict the median house price (the label) of a town given a series of attributes about the town.\n",
    "\n",
    "**Since we have data and labels, this is a supervised learning problem. And since we're trying to predict a number, it's a regression problem.**\n",
    "\n",
    "Knowing these two things, how do they line up on the Scikit-Learn machine learning algorithm cheat-sheet?\n",
    "\n",
    "Following the map through, knowing what we know, it suggests we try RidgeRegression. Let's chek it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try Ridge Regression Model\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# set up random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data. X to predict y\n",
    "X = boston_df.drop(\"target\", axis = 1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "#split in to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate Ridge model\n",
    "model = Ridge()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# check the score of Ridge model on test data\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#how do we improve this score?\n",
    "#what if Ridge was not working?\n",
    "#let us refer back map... https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to try EnsembleRegressors. Ensemble is another word for multiple models put together to make a decision.\n",
    "\n",
    "One of the most common and useful ensemble methods is the Random Forest. Known for its fast training and prediction times and adaptibility to different problems.\n",
    "\n",
    "The basic premise of the Random Forest is to combine a number of different decision trees, each one random from the other and make a prediction on a sample by averaging the result of each decision tree.\n",
    "\n",
    "An in-depth discussion of the Random Forest algorithm is beyond the scope of this notebook but if you're interested in learning more, An Implementation and Explanation of the Random Forest in Python by Will Koehrsen is a great read. https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76\n",
    "\n",
    "Since we're working with regression, we'll use Scikit-Learn's RandomForestRegressor.\n",
    "\n",
    "We can use the exact same workflow as above. Except for changing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8765210916447665"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let us try Random Forest Regressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#create the data. X to predict y\n",
    "X = boston_df.drop(\"target\", axis = 1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "#split in to train and test set\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate Random FOrest Regressor model\n",
    "rf = RandomForestRegressor() #n_estimators = 100 (to remove warning)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# check the score of Random Forest Regressor on test data\n",
    "rf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168522"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the Ridge model again\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 choosing an estimator for classification problem\n",
    "\n",
    "#scikit learn map: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease = pd.read_csv(\"heart-disease.csv\")\n",
    "heart_disease.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(heart_disease)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consulting the map and it says LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         0\n",
       "sex         0\n",
       "cp          0\n",
       "trestbps    0\n",
       "chol        0\n",
       "fbs         0\n",
       "restecg     0\n",
       "thalach     0\n",
       "exang       0\n",
       "oldpeak     0\n",
       "slope       0\n",
       "ca          0\n",
       "thal        0\n",
       "target      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "heart_disease.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the Boston housing dataset, here we want to use all of the available data to predict the target column (1 for if a patient has heart disease and 0 for if they don't).\n",
    "\n",
    "So what do we know?\n",
    "\n",
    "We've got 303 samples (1 row = 1 sample) and we're trying to predict whether or not a patient has heart disease.\n",
    "\n",
    "Because we're trying to predict whether each sample is one thing or another, we've got a classification problem.\n",
    "\n",
    "Following the cheat-sheet we end up at LinearSVC which stands for Linear Support Vector Classifier. Let's try it on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47540983606557374"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the LinearSVC estimator class\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# make the data. X to predict y\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#instantiate LinearSVC\n",
    "#clf means classifier\n",
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the LinearSVC # check the score of model on test data\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Straight out of the box (with no tuning or improvements) the model scores 47% accuracy, which with 2 classes (heart disease or not) is as good as guessing.\n",
    "\n",
    "With this result, we'll go back to our diagram and see what our options are.\n",
    "\n",
    "Following the path (and skipping a few, don't worry, we'll get to this) we come up to EnsembleMethods again. Except this time, we'll be looking at ensemble classifiers instead of regressors.\n",
    "\n",
    "Remember our RandomForestRegressor from above? We'll it has a dance partner, RandomForestClassifier which is an ensemble based machine model learning model for classification. You might be able to guess what we can use it for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# make the data. X to predict y\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#instantiate RandomForestClassifier\n",
    "#clf means classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100) #'n_estimators = 100' then no error will be seen, error bcoz of sklearn version difference\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the RandomForestClassifier # check the score of model on test data\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the RandomForestClassifier we get almost double the score of LinearSVC.\n",
    "\n",
    "One thing to remember, is both models are yet to receive any hyperparameter tuning. Hyperparameter tuning is fancy term for adjusting some settings on a model to try and make it better. It usually happens once you've found a decent baseline result you'd like to improve upon.\n",
    "\n",
    "In this case, we'd probably take the RandomForestClassifier and try and improve it with hyperparameter tuning (which we'll see later on)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the other models?\n",
    "Looking at the cheat-sheet and the examples above, you may have noticed we've skipped a few.\n",
    "\n",
    "Why?\n",
    "\n",
    "The first reason is time. Covering every single one would take a fair bit longer than what we've done here. And the second one is the effectiveness of ensemble methods.\n",
    "\n",
    "**A little tidbit for modelling in machine learning is:**\n",
    "\n",
    "* **If you have structured data (tables or dataframes), use ensemble methods, such as, a Random Forest.**\n",
    "* **If you have unstructured data (text, images, audio, things not in tables), use deep learning or transfer learning.**\n",
    "\n",
    "For this notebook, we're focused on structured data, which is why the Random Forest has been our model of choice.\n",
    "\n",
    "If you'd like to learn more about the Random Forest and why it's the war horse of machine learning, check out these resources:\n",
    "\n",
    "* Random Forest Wikipedia\n",
    "* Random Forests in Python by yhat\n",
    "* An Implementation and Explanation of the Random Forest in Python by Will Koehrsen\n",
    " \n",
    "Experiment until something works\n",
    "The beautiful thing is, the way the Scikit-Learn API is designed, once you know the way with one model, using another is much the same.\n",
    "\n",
    "And since a big part of being a machine learning engineer or data scientist is experimenting, you might want to try out some of the other models on the cheat-sheet and see how you go. The more you can reduce the time between experiments, the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering\n",
    "#0,1,2 done till now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. fit the model/algorithm and use it to make predictions on our data\n",
    "Now you've chosen a model, the next step is to have it learn from the data so it can be used for predictions in the future.\n",
    "\n",
    "If you've followed through, you've seen a few examples of this already.\n",
    "\n",
    "# 3.1 fitting the model to the data\n",
    "In Scikit-Learn, the process of having a machine learning model learn patterns from a dataset involves calling the fit() method and passing it data, such as, fit(X, y).\n",
    "\n",
    "Where X is a feature array and y is a target array.\n",
    "\n",
    "Other names for X include:\n",
    "\n",
    "* Data\n",
    "* Feature variables\n",
    "* Features\n",
    "\n",
    "Other names for y include:\n",
    "\n",
    "* Labels\n",
    "* Target variable\n",
    "\n",
    "**For supervised learning there is usually an X and y. For unsupervised learning, there's no y (no labels).**\n",
    "\n",
    "Let's revisit the example of using patient data (X) to predict whether or not they have heart disease (y).\n",
    "\n",
    "Different names for:\n",
    "* `X` = features, features variables, data\n",
    "* `y` = labels, targets, target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the RandomForestClassifier estimator class\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# make the data. X to predict y\n",
    "X = heart_disease.drop(\"target\", axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#instantiate RandomForestClassifier\n",
    "#clf means classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100) #'n_estimators = 100' then no error will be seen, error bcoz of sklearn version difference\n",
    "\n",
    "# fit the model to the data (training machine learning model)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the RandomForestClassifier # check the score of model on test data (use the patterns the model has lerned)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "Calling the fit() method will cause the machine learning algorithm to attempt to find patterns between X and y. Or if there's no y, it'll only find the patterns within X.\n",
    "\n",
    "Let's see X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  \n",
       "0   0     1  \n",
       "1   0     2  \n",
       "2   0     2  \n",
       "3   0     2  \n",
       "4   0     2  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298    0\n",
       "299    0\n",
       "300    0\n",
       "301    0\n",
       "302    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing X and y to fit() will cause the model to go through all of the examples in X (data) and see what their corresponding y (label) is.\n",
    "\n",
    "How the model does this is different depending on the model you use.\n",
    "\n",
    "Explaining the details of each would take an entire textbook.\n",
    "\n",
    "For now, you could imagine it similar to how you would figure out patterns if you had enough time.\n",
    "\n",
    "You'd look at the feature variables, X, the age, sex, chol (cholesterol) and see what different values led to the labels, y, 1 for heart disease, 0 for not heart disease.\n",
    "\n",
    "This concept, regardless of the problem, is similar throughout all of machine learning.\n",
    "\n",
    "**During training (finding patterns in data):**\n",
    "\n",
    "A machine learning algorithm looks at a dataset, finds patterns, tries to use those patterns to predict something and corrects itself as best it can with the available data and labels. It stores these patterns for later use.\n",
    "\n",
    "**During testing or in production (using learned patterns):**\n",
    "\n",
    "A machine learning algorithm uses the patterns its previously learned in a dataset to make a prediction on some unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest model deep dive\n",
    "These resources will help you understand what's happening inside the Random Forest models we've been using.\n",
    "\n",
    "* Random Forest Wikipedia\n",
    "* Random Forest Wikipedia (simple version)\n",
    "* Random Forests in Python by yhat\n",
    "* An Implementation and Explanation of the Random Forest in Python by Will Koehrsen\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Make predictions using machine learning model\n",
    "\n",
    "Now we've got a trained model, one which has hoepfully learned patterns in the data, you'll want to use it to make predictions.\n",
    "\n",
    "Scikit-Learn enables this in several ways. **Two of the most common and useful are predict() and predict_proba().**\n",
    "\n",
    "Let's see them in action.\n",
    "\n",
    "2 ways to make predictions:\n",
    "1. `predict()`\n",
    "2. `predict_proba()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5908053f578c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use a trained model to make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this doesn't work...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \"\"\"\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mproba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'estimators_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;31m# Check data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Assign chunk of trees to jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    357\u001b[0m                                  \"call `fit` before exploiting the model.\")\n\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[0;34m(self, X, check_input)\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[1;32m    393\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 7. 8. 3. 4.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "# Use a trained model to make predictions\n",
    "clf.predict(np.array([1, 7, 8, 3, 4])) # this doesn't work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>140</td>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>243</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "179   57    1   0       150   276    0        0      112      1      0.6   \n",
       "228   59    1   3       170   288    0        0      159      0      0.2   \n",
       "111   57    1   2       150   126    1        1      173      0      0.2   \n",
       "246   56    0   0       134   409    0        0      150      1      1.9   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "249   69    1   2       140   254    0        0      146      0      2.0   \n",
       "104   50    1   2       129   196    0        1      163      0      0.0   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "193   60    1   0       145   282    0        0      142      1      2.8   \n",
       "184   50    1   0       150   243    0        0      128      0      2.6   \n",
       "\n",
       "     slope  ca  thal  \n",
       "179      1   1     1  \n",
       "228      1   0     3  \n",
       "111      2   1     3  \n",
       "246      1   2     3  \n",
       "60       2   1     2  \n",
       "..     ...  ..   ...  \n",
       "249      1   3     3  \n",
       "104      2   0     2  \n",
       "300      1   2     3  \n",
       "193      1   2     3  \n",
       "184      1   0     3  \n",
       "\n",
       "[61 rows x 13 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "#X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf.predict(X_test.head()) # shows only 5 values as its head\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_test\n",
    "# fitting it in array\n",
    "np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given data in the form of X, the predict() function returns labels in the form of y.\n",
    "\n",
    "It's standard practice to save these predictions to a variable named something like y_preds for later comparison to y_test or y_true (usually same as y_test just another name)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare predictions to test/true/truth lables to evaluate the model\n",
    "y_preds = clf.predict(X_test)\n",
    "np.mean(y_preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from where does the above cell(0.85) number come from?\n",
    "# Returns the mean accuracy on the given test data and labels.(shift+ tab on 'clf.score')\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of doing this is with Scikit-Learn's accuracy_score() function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For the predict() function to work, it must be passed X (data) in the same format the model was trained on. Anything different and it will return an error.\n",
    "\n",
    "predict_proba() returns the probabilities of a classification label.\n",
    "\n",
    "Make predictions with predict_proba() - use this if someone asks you \"what's the probability your model is assigning to each prediction?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict() vs predict_proba()\n",
    " make predictions with predict_proba()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.89, 0.11],\n",
       "       [0.49, 0.51],\n",
       "       [0.43, 0.57],\n",
       "       [0.84, 0.16],\n",
       "       [0.18, 0.82]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict_proba() returns the probabilities of a classification model\n",
    "# return probabilities rather than lables\n",
    "clf.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's predict() on same data..\n",
    "clf.predict(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>276</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>170</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "179   57    1   0       150   276    0        0      112      1      0.6   \n",
       "228   59    1   3       170   288    0        0      159      0      0.2   \n",
       "111   57    1   2       150   126    1        1      173      0      0.2   \n",
       "246   56    0   0       134   409    0        0      150      1      1.9   \n",
       "60    71    0   2       110   265    1        0      130      0      0.0   \n",
       "\n",
       "     slope  ca  thal  \n",
       "179      1   1     1  \n",
       "228      1   0     3  \n",
       "111      2   1     3  \n",
       "246      1   2     3  \n",
       "60       2   1     2  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    165\n",
       "0    138\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease['target'].value_counts()\n",
    "# 1 for hear disease and 0 for not heart disese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making predictions with our model(regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict() can also be used for regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = boston_df.drop('target', axis = 1)\n",
    "y = boston_df['target']\n",
    "\n",
    "# split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate and fit model (learn the patterns, on training set)\n",
    "model = RandomForestRegressor(n_estimators = 100).fit(X_train, y_train)\n",
    "#model.fit(X_train, y_train) # combining with previous line\n",
    "\n",
    "#make predictions\n",
    "y_preds = model.predict(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.002, 30.826, 16.734, 23.467, 16.853, 21.725, 19.232, 15.239,\n",
       "       21.067, 20.738])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6, 22.8, 16.1, 20. , 17.8, 14. , 19.6, 16.8])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_test[:10])\n",
    "#y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1226372549019623"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compare the predictions to the truth/test/true\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now we've seen how to get a model how to find patterns in data using the fit() function and make predictions using what its learned using the predict() and predict_proba() functions, it's time to evaluate those predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating a machine learning model (score)\n",
    "\n",
    "Once you've trained a model, you'll want a way to measure how trustworthy its predictions are.\n",
    "\n",
    "Scikit-Learn implements 3 different methods of evaluating models.\n",
    "\n",
    "1. The score() method. Calling score() on a model instance will return a metric assosciated with the type of model you're using. The metric depends on which model you're using.\n",
    "2. The scoring parameter. This parameter can be passed to methods such as cross_val_score() or GridSearchCV() to tell Scikit-Learn to use a specific type of scoring metric.\n",
    "3. Problem-specific metric functions. Similar to how the scoring parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "\n",
    "The scoring function you use will also depend on the problem you're working on.\n",
    "\n",
    "Classification problems have different evaluation metrics and scoring functions to regression problems.\n",
    "\n",
    "Let's look at some examples.\n",
    "\n",
    "## 4.1 General model evaluation with score()\n",
    "If we bring down the code from our previous classification problem (building a classifier to predict whether or not someone has heart disease based on their medical records).\n",
    "\n",
    "We can see the score() method come into play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let us do the same but for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# create the data\n",
    "X = boston_df.drop('target', axis = 1)\n",
    "y = boston_df['target']\n",
    "\n",
    "# split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate and fit model (learn the patterns, on training set)\n",
    "model = RandomForestRegressor(n_estimators = 100).fit(X_train, y_train)\n",
    "#model.fit(X_train, y_train) # combining with previous line\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the score of the model (on the test set)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, model is an instance of RandomForestRegressor. And since it's a regression model, the default metric built into score() is the coefficient of determination or R^2 (pronounced R-sqaured).\n",
    "\n",
    "Remember, you can find this by pressing SHIFT + TAB within the brackets of score() when called on a model instance.\n",
    "\n",
    "The best possible value here is 1.0, this means the model predicts the target regression values exactly.\n",
    "\n",
    "Calling the score() method on any model instance and passing it test data is a good quick way to see how your model is going.\n",
    "\n",
    "However, when you get further into a problem, it's likely you'll want to start using more powerful metrics to evaluate your models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976679849361528"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating your models using the scoring parameter\n",
    "The next step up from using score() is to use a custom scoring parameter with cross_val_score() or GridSearchCV.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "As you may have guessed, the scoring parameter you set will be different depending on the problem you're working on.\n",
    "\n",
    "We'll see some specific examples of different parameters in a moment but first let's check out cross_val_score().\n",
    "\n",
    "To do so, we'll copy the heart disease classification code from above and then add another line at the top.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Import the RandomForestClassifier model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Split the data into X (features/data) and y (target/labels)\n",
    "X = heart_disease.drop(\"target\", axis=1)\n",
    "y = heart_disease[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Instantiate the model (on the training set)\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Call the fit method on the model and pass it training data\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross_val_score() is slightly different to score(). Let's see a code example first and then we'll go through the details.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8524590163934426"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82178218, 0.84158416, 0.78217822])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using cross_val_score()\n",
    "cross_val_score(clf,X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "The first difference you might notice is cross_val_score() returns an array where as score() only returns a single number.\n",
    "\n",
    "cross_val_score() returns an array because of a parameter called cv, which stands for cross-validation.\n",
    "\n",
    "When cv isn't set, cross_val_score() will return an array of 3 numbers by default (or 5 by default if you're using Scikit-Learn version 0.22+).\n",
    "\n",
    "Remember, you can see the parameters of a function using SHIFT + TAB from within the brackets.\n",
    "\n",
    "But wait, you might be thinking, what even is cross-validation?\n",
    "\n",
    "\n",
    "But looking deeper into this, if a model is trained using the training data or 80% of samples, this means 20% of samples aren't used for the model to learn anything.\n",
    "\n",
    "This also means depending on what 80% is used to train on and what 20% is used to evaluate the model, it may achieve a score which doesn't reflect the entire dataset. For example, if a lot of easy examples are in the 80% training data, when it comes to test on the 20%, your model may perform poorly. The same goes for the reverse.\n",
    "\n",
    "\n",
    "Not training on all the data\n",
    "Avoiding getting lucky scores on single splits of the data\n",
    "Instead of training only on 1 training split and evaluating on 1 testing split, 5-fold cross-validation does it 5 times. On a different split each time, returning a score for each.\n",
    "\n",
    "Why 5-fold?\n",
    "\n",
    "The actual name of this setup K-fold cross-validation. Where K is an abitrary number. We've used 5 because it looks nice visually, and will be the default in Scikit-Learn from version 0.22 onwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.8852459 , 0.7704918 , 0.8       , 0.75      ])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#without 'cv=5' we are getting error. read documentation shitft+tab\n",
    "# 'cv=5' makes 5 different splits\n",
    "cross_val_score(clf,X,y, cv=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we set cv=5 (5-fold cross-validation), we get back 5 different scores instead of 1.\n",
    "\n",
    "Taking the mean of this array gives us a more in-depth idea of how our model is performing by converting the 5 scores into one.\n",
    "\n",
    "Notice, the average cross_val_score() is slightly lower than single value returned by score()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90322581, 0.80645161, 0.83870968, 0.90322581, 0.90322581,\n",
       "       0.8       , 0.73333333, 0.86666667, 0.72413793, 0.79310345])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf,X,y, cv=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8524590163934426, 0.8248087431693989)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# single training adn test split score\n",
    "clf_single_score = clf.score(X_test, y_test)\n",
    "\n",
    "# take the of 5 fold cross_validation_score\n",
    "clf_cross_val_score = np.mean(cross_val_score(clf, X, y, cv=5))\n",
    "\n",
    "# compare the two\n",
    "clf_single_score, clf_cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, if you were asked to report the accuracy of your model, even though it's lower, you'd prefer the cross-validated metric over the non-cross-validated metric.\n",
    "\n",
    "We haven't used the scoring parameter at all.\n",
    "\n",
    "By default, it's set to None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "score() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-cca012993b3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Default scoring parameter of classifier = mean accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: score() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "# Default scoring parameter of classifier = mean accuracy\n",
    "clf.score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(clf, X, y, cv=5, scoring=None) # default scoring\n",
    "# value slight different as seed not set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When scoring is set to None (by default), it uses the same metric as score() for whatever model is passed to cross_val_score().\n",
    "\n",
    "In this case, our model is clf which is an instance of RandomForestClassifier which uses mean accuracy as the default score() metric.\n",
    "\n",
    "You can change the evaluation score cross_val_score() uses by changing the scoring parameter.\n",
    "\n",
    "And as you might have guessed, different problems call for different evaluation scores.\n",
    "\n",
    "The Scikit-Learn documentation outlines a vast range of evaluation metrics for different problems but let's have a look at a few.\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2.1 Classification model evaluation metrics\n",
    "Four of the main evaluation metrics/methods you'll come across for classification models are:\n",
    "\n",
    "1. Accuracy\n",
    "2. Area under ROC curve\n",
    "3. Confusion matrix\n",
    "4. Classification report\n",
    "\n",
    "Let's have a look at each of these. We'll bring down the classification code from above to go through some examples.\n",
    "\n",
    "**Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "0     63    1   3       145   233    1        0      150      0      2.3   \n",
       "1     37    1   2       130   250    0        1      187      0      3.5   \n",
       "2     41    0   1       130   204    0        0      172      0      1.4   \n",
       "3     56    1   1       120   236    0        1      178      0      0.8   \n",
       "4     57    0   0       120   354    0        1      163      1      0.6   \n",
       "..   ...  ...  ..       ...   ...  ...      ...      ...    ...      ...   \n",
       "298   57    0   0       140   241    0        1      123      1      0.2   \n",
       "299   45    1   3       110   264    0        1      132      0      1.2   \n",
       "300   68    1   0       144   193    1        1      141      0      3.4   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "302   57    0   1       130   236    0        0      174      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "0        0   0     1       1  \n",
       "1        0   0     2       1  \n",
       "2        2   0     2       1  \n",
       "3        2   0     2       1  \n",
       "4        2   0     2       1  \n",
       "..     ...  ..   ...     ...  \n",
       "298      1   0     3       0  \n",
       "299      1   0     3       0  \n",
       "300      1   2     3       0  \n",
       "301      1   1     3       0  \n",
       "302      1   1     2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_disease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import cross_val_score from the model_selection module\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "cross_val_score = cross_val_score(clf, X, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248087431693989"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**\n",
    "\n",
    "Accuracy is the default metric for the score() function within each of Scikit-Learn's classifier models. And it's probably the metric you'll see most often used for classification problems.\n",
    "\n",
    "However, we'll see in a second how it may not always be the best metric to use.\n",
    "\n",
    "Scikit-Learn returns accuracy as a decimal but you can easily convert it to a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart Disease Classifier Cross-Validated Accuracy: 82.48%\n"
     ]
    }
   ],
   "source": [
    "#accuracy as percentage\n",
    "print(f\"Heart Disease Classifier Cross-Validated Accuracy: {np.mean(cross_val_score) *100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating a classification model 2 (ROC/AUC curve)\n",
    "Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "If this one sounds like a mouthful, its because reading the full name is.\n",
    "\n",
    "It's usually referred to as AUC for Area Under Curve and the curve they're talking about is the Receiver Operating Characteristic or ROC for short.\n",
    "\n",
    "**Area under the receiver operating characteristic curve (AUC/ROC)**\n",
    "\n",
    "* Area under curve (AUC)\n",
    "* ROC curv\n",
    "\n",
    "So if hear someone talking about AUC or ROC, they're probably talking about what follows.\n",
    "\n",
    "ROC curves are a comparison of true postive rate (tpr) versus false positive rate (fpr).\n",
    "\n",
    "For clarity:\n",
    "\n",
    "* True positive = model predicts 1 when truth is 1\n",
    "* False positive = model predicts 1 when truth is 0\n",
    "* True negative = model predicts 0 when truth is 0\n",
    "* False negative = model predicts 0 when truth is 1\n",
    "\n",
    "Now we know this, let's see one. Scikit-Learn lets you calculate the information required for a ROC curve using the roc_curve function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create X_test... etc\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.51, 0.49],\n",
       "        [0.17, 0.83],\n",
       "        [0.51, 0.49],\n",
       "        [0.72, 0.28],\n",
       "        [0.43, 0.57],\n",
       "        [0.12, 0.88],\n",
       "        [0.3 , 0.7 ],\n",
       "        [0.97, 0.03],\n",
       "        [0.15, 0.85],\n",
       "        [0.4 , 0.6 ]]), 61)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# fit the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions with probabilities\n",
    "y_probs = clf.predict_proba(X_test)\n",
    "\n",
    "y_probs[:10], len(y_probs)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49, 0.83, 0.49, 0.28, 0.57, 0.88, 0.7 , 0.03, 0.85, 0.6 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_probs_positive = y_probs[:,1] # column 1 of every row\n",
    "y_probs_positive[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.03448276, 0.03448276, 0.03448276, 0.03448276,\n",
       "       0.03448276, 0.03448276, 0.06896552, 0.06896552, 0.06896552,\n",
       "       0.10344828, 0.10344828, 0.13793103, 0.13793103, 0.13793103,\n",
       "       0.20689655, 0.20689655, 0.20689655, 0.27586207, 0.37931034,\n",
       "       0.37931034, 0.48275862, 0.48275862, 0.55172414, 0.55172414,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate fpr, tpr, and thresholds\n",
    "fpr,tpr, thresholds, = roc_curve(y_test, y_probs_positive)\n",
    "\n",
    "# check the false positive rates\n",
    "fpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these on their own doesn't make much sense. It's much easier to see their value visually.\n",
    "\n",
    "Since Scikit-Learn doesn't have a built-in function to plot a ROC curve, quite often, you'll find a function (or write your own) like the one below.\n",
    "\n",
    "# Evaluating a classification model 3 (ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a function for plotting ROC curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "    \"\"\"\n",
    "    plots a ROC curve given the false positive rate(fpr)\n",
    "    and true positive rate (tpr) of a model\n",
    "    \"\"\"\n",
    "    # plot roc curve\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    # plot line with no predictive power (baseline)\n",
    "    plt.plot([0,1], [0,1], color='darkblue', linestyle='--', label='Guessing')\n",
    "    \n",
    "    #customize the plot\n",
    "    plt.xlabel(\"False positive rate (fpr)\")\n",
    "    plt.ylabel(\"True positive rate (tpr)\")\n",
    "    plt.title(\"Receiver operating characteristic (ROC) curve\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "              \n",
    "              \n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot for the first time, it might seem a bit confusing.\n",
    "\n",
    "The main thing to take away here is our model is doing far better than guessing.\n",
    "\n",
    "A metric you can use to quantify the ROC curve in a single number is AUC (Area Under Curve). Scikit-Learn implements a function to caculate this called roc_auc_score().\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score\n",
    "\n",
    "The maximum ROC AUC score you can achieve is 1.0 and generally, the closer to 1.0, the better the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8669181034482759"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_test, y_probs_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most ideal position for a ROC curve to run along the top left corner of the plot.\n",
    "\n",
    "This would mean the model predicts only true positives and no false positives. And would result in a ROC AUC score of 1.0.\n",
    "\n",
    "You can see this by creating a ROC curve using only the y_test labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot perfect ROC curve and AUC score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfect AUC score\n",
    "roc_auc_score(y_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, a perfect ROC curve is unlikely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a classification model 4(confusion matrix)\n",
    "**confusion matrix**\n",
    "\n",
    "The next way to evaluate a classification model is by using a confusion matrix.\n",
    "\n",
    "https://en.wikipedia.org/wiki/Confusion_matrix\n",
    "\n",
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. \n",
    "\n",
    "In essence, giving you an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[23,  6],\n",
       "       [ 6, 26]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "confusion_matrix(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, this is probably easier visualized.\n",
    "\n",
    "One way to do it is with pd.crosstab()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Labels</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Labels</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Labels   0   1\n",
       "Actual Labels           \n",
       "0                 23   6\n",
       "1                  6  26"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize confusion matrix with pd.crosstab()\n",
    "pd.crosstab(y_test,\n",
    "            y_preds,\n",
    "           rownames=['Actual Labels'],\n",
    "           colnames=['Predicted Labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "22 + 7 + 5 + 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(X_test))\n",
    "print(len(y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1d0dfc18>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make our confusion matrix more visual with seaborn's heatmap()\n",
    "import seaborn as sns\n",
    "\n",
    "# set the font scale\n",
    "sns.set(font_scale = 1.5)\n",
    "\n",
    "# create a confusion matrix\n",
    "conf_mat = confusion_matrix(y_test, y_preds)\n",
    "\n",
    "# plot it using seaborn\n",
    "sns.heatmap(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh.. that plot isn't offering much. Let's add some commucation and functionise it.\n",
    "\n",
    "\n",
    "# evaluating a classification model 5(confusion matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_conf_mat(conf_mat):\n",
    "    \"\"\"\n",
    "    plots a confusion matrix using seaborn's heatmap()\n",
    "    \"\"\"\n",
    "    \n",
    "    flg,ax = plt.subplots(figsize=(3,3))\n",
    "    ax = sns.heatmap(conf_mat,\n",
    "                    annot=True, #Annotate the boxes with conf_mat info\n",
    "                    cbar=False)\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Predicted Label')\n",
    "    \n",
    "    # fix the broken annotation (this happened in matplotlib 3.1.1)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom + 0.5, top -0.5)\n",
    "    \n",
    "plot_conf_mat(conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ideal confusion matrix no values out of the diagonal. This means all of models predictions match the actual labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create perfect confusion matrix\n",
    "perfect_conf_mat = confusion_matrix(y_test, y_test)\n",
    "plot_conf_mat(perfect_conf_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn has an implementation of plotting a confusion matrix in plot_confusion_matrix(), however, the documentation on it isn't complete (at the time of writing).\n",
    "\n",
    "And trying to import it returns an error.\n",
    "\n",
    "You can try to use it but beware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-efa54a104b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Returns an error.... (at time of writing)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplot_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_confusion_matrix' from 'sklearn.metrics' (/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "# Returns an error.... (at time of writing)\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(clf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating a classification model 6(classification report)\n",
    "**Classification report**\n",
    "\n",
    "The final major metric you should consider when evaluating a classification model is a classification report.\n",
    "\n",
    "A classification report is more so a collection of metrics rather than a single one.\n",
    "\n",
    "You can create a classification report using Scikit-Learn's classification_report() function.\n",
    "\n",
    "Let's see one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.79      0.79        29\n",
      "           1       0.81      0.81      0.81        32\n",
      "\n",
      "    accuracy                           0.80        61\n",
      "   macro avg       0.80      0.80      0.80        61\n",
      "weighted avg       0.80      0.80      0.80        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "It returns four columns: precision, recall, f1-score and support.\n",
    "\n",
    "The number of rows will depend on how many different classes there are. But there will always be three rows labell accuracy, macro avg and weighted avg.\n",
    "\n",
    "Each term measures something slightly different:\n",
    "\n",
    "* **Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "* **Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "* **F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "* **Support** - The number of samples each metric was calculated on.\n",
    "* **Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0, in other words, getting the prediction right 100% of the time.\n",
    "* **Macro avg** - Short for macro average, the average precision, recall and F1 score between classes. Macro avg doesn't take class imbalance into account. So if you do have class imbalances (more examples of one class than another), you should pay attention to this.\n",
    "* **Weighted avg** - Short for weighted average, the weighted average precision, recall and F1 score between classes. Weighted means each metric is calculated with respect to how many samples there are in each class. This metric will favour the majority class (e.g. it will give a high value when one class out performs another due to having more samples).\n",
    "\n",
    "When should you use each?\n",
    "\n",
    "It can be tempting to base your classification models perfomance only on accuracy. And accuracy is a good metric to report, except when you have very imbalanced classes.\n",
    "\n",
    "For example, let's say there were 10,000 people. And 1 of them had a disease. You're asked to build a model to predict who has it.\n",
    "\n",
    "You build the model and find your model to be 99.99% accurate. Which sounds great! ...until you realise, all its doing is predicting no one has the disease, in other words all 10,000 predictions are false.\n",
    "\n",
    "In this case, you'd want to turn to metrics such as precision, recall and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499950</td>\n",
       "      <td>0.99980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.99990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.99995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.99985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>9999.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0.0  1.0  accuracy     macro avg  weighted avg\n",
       "precision     0.99990  0.0    0.9999      0.499950       0.99980\n",
       "recall        1.00000  0.0    0.9999      0.500000       0.99990\n",
       "f1-score      0.99995  0.0    0.9999      0.499975       0.99985\n",
       "support    9999.00000  1.0    0.9999  10000.000000   10000.00000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Where precision and recall become valuable\n",
    "disease_true = np.zeros(10000)\n",
    "disease_true[0] = 1 # only one positive case\n",
    "\n",
    "disease_preds = np.zeros(10000) # model predicts every case as 0\n",
    "\n",
    "pd.DataFrame(classification_report(disease_true,\n",
    "                                   disease_preds,\n",
    "                                   output_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here, we've got an accuracy of 0.9999 (99.99%), great precision and recall on class 0.0 but nothing for class 1.0.\n",
    "\n",
    "Ask yourself, although the model achieves 99.99% accuracy, is it useful?\n",
    "\n",
    "To summarize classification metrics:\n",
    "\n",
    "* **Accuracy** is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1).\n",
    "* **Precision** and **recall** become more important when classes are imbalanced.\n",
    "\n",
    "If false positive predictions are worse than false negatives, aim for higher precision.\n",
    "\n",
    "If false negative predictions are worse than false positives, aim for higher recall.\n",
    "\n",
    "* **F1-score** is a combination of precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  evaluation a Regression model 1 (R2score)\n",
    "# 4.2.2 Regression model evaluation metricsÂ¶\n",
    "\n",
    "Similar to classification, there are several metrics you can use to evaluate your regression models.... https://scikit-learn.org/stable/modules/model_evaluation.html#regression-metrics\n",
    "\n",
    "Model evaluation metrics documentation... https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "We'll check out the following.\n",
    "\n",
    "**1. R^2 (pronounced r-squared) or coefficient of determination** - Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.\n",
    "\n",
    "**2. Mean absolute error (MAE)** - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "\n",
    "**3. Mean squared error (MSE)** - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "\n",
    "Let's see them in action. First, we'll bring down our regression model code again.\n",
    "\n",
    "**R^2**\n",
    "\n",
    "What R-squared does: Compares your models predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, it's R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the RandomForestRegressor model class from the ensemble module\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Setup random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create the data\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Institate and fit the model (on the training set)\n",
    "model = RandomForestRegressor(n_estimators = 100)\n",
    "model.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**R^2 Score (coefficient of determination)**\n",
    "\n",
    "Once you've got a trained regression model, the default evaluation metric in the score() function is R^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.873969014117403"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the models R^2 score\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outside of the score() function, R^2 can be calculated using Scikit-Learn's r2_score() function.\n",
    "\n",
    "A model which only predicted the mean would get a score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "#fill an array with y_test mean\n",
    "y_test_mean = np.full(len(y_test), y_test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.488235294117654"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(y_test)\n",
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.220446049250313e-16"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model only predicting the mean gets an R^2 score of 0\n",
    "r2_score(y_test, y_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model predicting perfectly the correct values gets an R^2 score of 1\n",
    "r2_score(y_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For your regression models, you'll want to maximise R^2, whilst minimising MAE and MSE.\n",
    "\n",
    "# evaluating a regression model 2 (MAE)\n",
    "**Mean absolue error (MAE)**\n",
    "\n",
    "MAE is the average of the aboslute differences between predictions and actual values. It gives you an idea of how wrong your models predictions are.\n",
    "\n",
    "A model's mean absolute error can be calculated with Scikit-Learn's mean_absolute_error() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1226372549019623"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean absolute error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#evaluation metrics are always comparing truth lables to predicted labels\n",
    "y_preds = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_preds)\n",
    "mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieves an MAE of 2.122. This means, on average our models predictions are 2.122 units away from the actual value.\n",
    "\n",
    "Let's make it a little more visual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data ={'actual_values': y_test,\n",
    "                        'predicted_values': y_preds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_values</th>\n",
       "      <th>predicted_values</th>\n",
       "      <th>Differences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>23.6</td>\n",
       "      <td>23.002</td>\n",
       "      <td>-0.598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.826</td>\n",
       "      <td>-1.574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.734</td>\n",
       "      <td>3.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.467</td>\n",
       "      <td>0.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.853</td>\n",
       "      <td>0.753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>17.9</td>\n",
       "      <td>13.030</td>\n",
       "      <td>-4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>9.6</td>\n",
       "      <td>12.490</td>\n",
       "      <td>2.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>17.2</td>\n",
       "      <td>13.406</td>\n",
       "      <td>-3.794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>22.5</td>\n",
       "      <td>20.219</td>\n",
       "      <td>-2.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>21.4</td>\n",
       "      <td>23.898</td>\n",
       "      <td>2.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual_values  predicted_values  Differences\n",
       "173           23.6            23.002       -0.598\n",
       "274           32.4            30.826       -1.574\n",
       "491           13.6            16.734        3.134\n",
       "72            22.8            23.467        0.667\n",
       "452           16.1            16.853        0.753\n",
       "..             ...               ...          ...\n",
       "412           17.9            13.030       -4.870\n",
       "436            9.6            12.490        2.890\n",
       "411           17.2            13.406       -3.794\n",
       "86            22.5            20.219       -2.281\n",
       "75            21.4            23.898        2.498\n",
       "\n",
       "[102 rows x 3 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df\n",
    "df['Differences'] = df['predicted_values'] - df['actual_values']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not included in video\n",
    "# fig, ax = plt.subplots()\n",
    "# x = np.arange(0, len(df), 1)\n",
    "# ax.scatter(x, df[\"actual_values\"], c='b', label=\"Acutual_Values\")\n",
    "# ax.scatter(x, df[\"predicted_values\"], c='r', label=\"predicted_values\")\n",
    "# ax.legend(loc=(1, 0.5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Evaluating a regression model 3 (MSE)\n",
    "\n",
    "**Mean squared error (MSE)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.242328990196082"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_preds)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.24232899019608"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate MSE by hand\n",
    "squared = np.square(df['Differences'])\n",
    "squared.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE will always be higher than MAE because is squares the errors rather than only taking the absolute difference into account.\n",
    "\n",
    "Now you might be thinking, which regression evaluation metric should you use?\n",
    "\n",
    "* R^2 is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your R^2 value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "* MAE gives a better indication of how far off each of your model's predictions are on average.\n",
    "* As for MAE or MSE, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
    "    * Pay more attention to MAE: When being \\$10,000 off is ***twice*** as bad as being \\$5,000 off.\n",
    "    * Pay more attention to MSE: When being \\$10,000 off is ***more than twice*** as bad as being \\$5,000 off.\n",
    "\n",
    "Note: What we've covered here is only a handful of potential metrics you can use to evaluate your models. If you're after a complete list, check out the Scikit-Learn metrics and scoring documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  machine learning model evaluation\n",
    "Evaluating the results of a machine learning model is as important as building one.\n",
    "\n",
    "But just like how different problems have different machine learning models, different machine learning models have different evaluation metrics.\n",
    "\n",
    "Below are some of the most important evaluation metrics you'll want to look into for classification and regression models.\n",
    "\n",
    "**Classification Model Evaluation Metrics/Techniques**\n",
    "\n",
    "**Accuracy** - The accuracy of the model in decimal form. Perfect accuracy is equal to 1.0.\n",
    "\n",
    "**Precision** - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "\n",
    "**Recall** - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "\n",
    "**F1 score** - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "\n",
    "**Confusion matrix** - Compares the predicted values with the true values in a tabular way, if 100% correct, all values in the matrix will be top left to bottom right (diagonal line).\n",
    "\n",
    "**Cross-validation** - Splits your dataset into multiple parts and train and tests your model on each part then evaluates performance as an average.\n",
    "\n",
    "**Classification report** - Sklearn has a built-in function called classification_report() which returns some of the main classification metrics such as precision, recall and f1-score.\n",
    "\n",
    "**ROC Curve** - Also known as receiver operating characteristic is a plot of true positive rate versus false-positive rate.\n",
    "\n",
    "**Area Under Curve (AUC) Score** - The area underneath the ROC curve. A perfect model achieves an AUC score of 1.0.\n",
    "\n",
    "**Which classification metric should you use?**\n",
    "\n",
    "**Accuracy** is a good measure to start with if all classes are balanced (e.g. same amount of samples which are labelled with 0 or 1).\n",
    "\n",
    "**Precision and recall** become more important when classes are imbalanced.\n",
    "\n",
    "If false-positive predictions are worse than false-negatives, aim for higher precision.\n",
    "\n",
    "If false-negative predictions are worse than false-positives, aim for higher recall.\n",
    "\n",
    "**F1-score** is a combination of precision and recall.\n",
    "\n",
    "A confusion matrix is always a good way to visualize how a classification model is going.\n",
    "\n",
    "**Regression Model Evaluation Metrics/Techniques**\n",
    "\n",
    "**R^2 (pronounced r-squared) or the coefficient of determination** - Compares your model's predictions to the mean of the targets. Values can range from negative infinity (a very poor model) to 1. For example, if all your model does is predict the mean of the targets, its R^2 value would be 0. And if your model perfectly predicts a range of numbers it's R^2 value would be 1.\n",
    "\n",
    "**Mean absolute error (MAE)** - The average of the absolute differences between predictions and actual values. It gives you an idea of how wrong your predictions were.\n",
    "\n",
    "**Mean squared error (MSE)** - The average squared differences between predictions and actual values. Squaring the errors removes negative errors. It also amplifies outliers (samples which have larger errors).\n",
    "\n",
    "**Which regression metric should you use?**\n",
    "\n",
    "**R2** is similar to accuracy. It gives you a quick indication of how well your model might be doing. Generally, the closer your **R2** value is to 1.0, the better the model. But it doesn't really tell exactly how wrong your model is in terms of how far off each prediction is.\n",
    "\n",
    "**MAE** gives a better indication of how far off each of your model's predictions are on average.\n",
    "\n",
    "As for **MAE** or **MSE**, because of the way MSE is calculated, squaring the differences between predicted values and actual values, it amplifies larger differences. Let's say we're predicting the value of houses (which we are).\n",
    "\n",
    "    * Pay more attention to MAE: When being $10,000 off is twice as bad as being $5,000 off.\n",
    "\n",
    "    * Pay more attention to MSE: When being $10,000 off is more than twice as bad as being $5,000 off.\n",
    "\n",
    "For more resources on evaluating a machine learning model, be sure to check out the following resources:\n",
    "\n",
    "Scikit-Learn documentation for metrics and scoring (quantifying the quality of predictions)\n",
    "\n",
    "Beyond Accuracy: Precision and Recall by Will Koehrsen\n",
    "\n",
    "Stack Overflow answer describing MSE (mean squared error) and RSME (root mean squared error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # evaluating a model with cross validation and scoring parameter\n",
    "# 4.2.3 finally using scoring parameter\n",
    "Woah. We've covered a bunch but haven't even touched the scoring parameter...\n",
    "\n",
    "As a refresh, the scoring parameter can be used with a function like cross_val_score() to tell Scikit-Learn what evaluation metric to return using cross-validation.\n",
    "\n",
    "## **Let's check it out with our classification model and the heart disease dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll use the default, which is mean accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81967213, 0.90163934, 0.83606557, 0.78333333, 0.78333333])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train 5 models set and evaluate them on different test sets  \n",
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring = None)\n",
    "cv_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've seen this before, now we got 5 different accuracy scores on different test splits of the data.\n",
    "\n",
    "Averaging this gives the cross-validated accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.48%\n"
     ]
    }
   ],
   "source": [
    "# cross validated accuracy \n",
    "#np.mean(cv_acc)\n",
    "print(f'The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the same using the scoring parameter and passing it \"accuracy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cross-validated accuracy is: 82.48%\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_acc = cross_val_score(clf, X, y, cv=5, scoring = 'accuracy')\n",
    "#cv_acc\n",
    "print(f'The cross-validated accuracy is: {np.mean(cv_acc)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for the other metrics we've been using for classification.\n",
    "\n",
    "Let's try \"precision\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8209201193072161"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precision\n",
    "cv_precision = cross_val_score(clf, X, y, cv=5, scoring='precision')\n",
    "#cv_precision\n",
    "np.mean(cv_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424242424242424"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recall\n",
    "cv_recall = cross_val_score(clf, X, y, cv=5, scoring='recall')\n",
    "#cv_recall\n",
    "np.mean(cv_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "# cv_recall = cross_val_score(clf, X, y, cv=5, scoring=\"recall\")\n",
    "# np.mean(cv_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8231854226519981"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# f1 or f1 score\n",
    "cv_f1 = cross_val_score(clf, X, y, cv = 5, scoring='f1')\n",
    "np.mean(cv_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat this process with our regression metrics.\n",
    "# Lets check out regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = boston_df.drop('target', axis = 1)\n",
    "y = boston_df['target']\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76861165, 0.85851765, 0.74941131, 0.47891315, 0.25642166])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.score() # shitf+tab\n",
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=5, scoring = None)\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76861165, 0.85851765, 0.74941131, 0.47891315, 0.25642166])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "cv_r2 = cross_val_score(model, X, y, cv=5, scoring = 'r2')\n",
    "cv_r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can use \"neg_mean_absolute_error\" for MAE (mean absolute error)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.06211765, -2.5060396 , -3.35824752, -3.81479208, -3.20442574])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean absolute error\n",
    "cv_mae = cross_val_score(model, X, y, cv=5, scoring = 'neg_mean_absolute_error')\n",
    "cv_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the \"neg_\"?\n",
    "\n",
    "Because Scikit-Learn documentation states:\n",
    "\n",
    "\"All scorer objects follow the convention that higher return values are better than lower return values.\"\n",
    "https://scikit-learn.org/stable/modules/model_evaluation.html#common-cases-predefined-values\n",
    "\n",
    "Which in this case, means a lower negative value (closer to 0) is better.\n",
    "\n",
    "What about \"neg_mean_squared_error\" for MSE (mean squared error)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -7.39124675, -12.80369927, -21.44045174, -46.88481495,\n",
       "       -19.38141243])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean squared error\n",
    "cv_mse = cross_val_score(model, X, y, cv = 5, scoring = 'neg_mean_squared_error')\n",
    "cv_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.580325026247316"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating a model with scikit learn functions\n",
    "## 4.3 Using different evaluation metrics with Scikit-Learn\n",
    "Remember the third way of evaluating Scikit-Learn functions?\n",
    "\n",
    "    1. Problem-specific metric functions. Similar to how the scoring parameter can be passed different scoring functions, Scikit-Learn implements these as stand alone functions.\n",
    "Well, we've kind of covered this third way of using evaulation metrics with Scikit-Learn.\n",
    "\n",
    "In essence, all of the metrics we've seen previously have their own function in Scikit-Learn.\n",
    "\n",
    "They all work by comparing an array of predictions, usually called y_preds to an array of actual labels, usually called y_test or y_true.\n",
    "\n",
    "Classification functions\n",
    "For:\n",
    "\n",
    "* Accuracy we can use accuracy_score()\n",
    "* Precision we can use precision_score()\n",
    "* Recall we can use recall_score()\n",
    "* F1 we can use f1_score()\n",
    "\n",
    "**Classification evaluation functions**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier metrics on the test set\n",
      "Accuracy: 85.25%\n",
      "Precision: 0.8484848484848485\n",
      "Recall: 0.875\n",
      "F1: 0.8615384615384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = heart_disease.drop('target', axis = 1)\n",
    "y = heart_disease['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make some predictions\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "# evaluate the classifier\n",
    "print(\"Classifier metrics on the test set\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_preds)*100:.2f}%\")\n",
    "print(f\"Precision: {precision_score(y_test, y_preds)}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_preds)}\")\n",
    "print(f\"F1: {f1_score(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for the regression problem.\n",
    "\n",
    "**Regression metrics**\n",
    "For:\n",
    "\n",
    "* R^2 we can use r2_score()\n",
    "* MAE (mean absolute error) we can use mean_absolute_error()\n",
    "* MSE (mean squared error) we can use mean_squared_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression model metrics on the test set\n",
      "R^2: 0.8739690141174031\n",
      "MAE: 2.1226372549019623\n",
      "MSE: 9.242328990196082\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "X = boston_df.drop(\"target\", axis=1)\n",
    "y = boston_df[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using our regression model\n",
    "y_preds = model.predict(X_test)\n",
    "\n",
    "# Evaluate the regression model\n",
    "print(\"Regression model metrics on the test set\")\n",
    "print(f\"R^2: {r2_score(y_test, y_preds)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_preds)}\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_preds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. improving a model (hyperparameter tuning)\n",
    "The first predictions you make with a model are generally referred to as baseline predictions. The same goes with the first evaluation metrics you get. These are generally referred to as baseline metrics.\n",
    "\n",
    "Your next goal is to improve upon these baseline metrics.\n",
    "\n",
    "Two of the main methods to improve baseline metrics are from a data perspective and a model perspective.\n",
    "\n",
    "From a data perspective asks:\n",
    "\n",
    "    * Could we collect more data? In machine learning, more data is generally better, as it gives a model more opportunities to learn patterns.\n",
    "    * Could we improve our data? This could mean filling in misisng values or finding a better encoding (turning things into numbers) strategy.\n",
    "From a model perspective asks:\n",
    "\n",
    "    * Is there a better model we could use? If you've started out with a simple model, could you use a more complex one? (we saw an example of this when looking at the Scikit-Learn machine learning map, ensemble methods are generally considered more complex models)\n",
    "    * Could we improve the current model? If the model you're using performs well straight out of the box, can the hyperparameters be tuned to make it even better?\n",
    "**Note**: Patterns in data are also often referred to as data parameters. The difference between parameters and hyperparameters is a machine learning model seeks to find parameters in data on its own, where as, hyperparameters are settings on a model which a user (you) can adjust.\n",
    "\n",
    "Since we have two existing datasets, we'll come at exploration from a model perspective.\n",
    "\n",
    "More specifically, we'll look at how we could improve our RandomForestClassifier and RandomForestRegressor models through hyperparameter tuning.\n",
    "\n",
    "What even are hyperparameters?\n",
    "\n",
    "Good question, let's check it out. First, we'll instantiate a RandomForestClassifier.\n",
    "\n",
    "________________________________________________________________________________________________\n",
    "\n",
    "First predictions = baseline predictions. First model = baseline model.\n",
    "\n",
    "From a data perspective:\n",
    "\n",
    "* Could we collect more data? (generally, the more data, the better)\n",
    "* Could we improve our data?\n",
    "\n",
    "From a model perspective:\n",
    "\n",
    "* Is there a better model we could use?\n",
    "* Could we improve the current model?\n",
    "\n",
    "Hyperparameters vs. Parameters\n",
    "\n",
    "* Parameters = model find these patterns in data\n",
    "* Hyperparameters = settings on a model you can adjust to (potentially) improve its ability to find patterns\n",
    "\n",
    "Three ways to adjust hyperparameters:\n",
    "\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to find hyperparameter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#instantiate\n",
    "clf = RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "When you instantiate a model like above, you're using the default hyperparameters.\n",
    "\n",
    "These get printed out when you call the model instance and get_params()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling hyperparameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll see things like max_depth, min_samples_split, n_estimators.\n",
    "\n",
    "Each of these is a hyperparameter of the RandomForestClassifier you can adjust.\n",
    "\n",
    "You can think of hyperparameters as being similar to dials on an oven. On the default setting your oven might do an okay job cooking your favourite meal. But with a little experimentation, you find it does better when you adjust the settings.\n",
    "\n",
    "\n",
    "The same goes for imporving a machine learning model by hyperparameter tuning. The default hyperparameters on a machine learning model may find patterns in data well. But there's a chance a adjusting the hyperparameters may improve a models performance.\n",
    "\n",
    "Every machine learning model will have different hyperparameters you can tune.\n",
    "\n",
    "You might be thinking, \"how the hell do I remember all of these?\"\n",
    "\n",
    "And it's a good question. It's why we're focused on the Random Forest. Instead of memorizing all of the hyperparameters for every model, we'll see how it's done with one. And then knowing these principles, you can apply them to a different model if needed.\n",
    "\n",
    "Reading the Scikit-Learn documentation for the Random Forest, you'll find they suggest trying to change n_estimators (the number of trees in the forest) and min_samples_split (the minimum number of samples required to split an internal node).\n",
    "\n",
    "We'll try tuning these as well as:\n",
    "\n",
    "* max_features (the number of features to consider when looking for the best split)\n",
    "* max_depth (the maximum depth of the tree)\n",
    "* min_samples_leaf (the minimum number of samples required to be at a leaf node)\n",
    "If this still sounds like a lot, the good news is, the process we're taking with the Random Forest and tuning its hyperparameters, can be used for other machine learning models in Scikit-Learn. The only difference is, with a different model, the hyperparameters you tune will be different.\n",
    "\n",
    "Adjusting hyperparameters is usually an experimental process to figure out which are best. As there's no real way of knowing which hyperparameters will be best when starting out.\n",
    "\n",
    "To get familar with hyparameter tuning, we'll take our RandomForestClassifier and adjust its hyperparameters in 3 ways.\n",
    "1. By hand\n",
    "2. Randomly with RandomSearchCV\n",
    "3. Exhaustively with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tuning hyperparameters\n",
    "# 5.1 tuning hyperparameters by hand \n",
    "# Let's make 3 sets, training, validation and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've worked with training and test datasets.\n",
    "\n",
    "You train a model on a training set and evaluate it on a test dataset.\n",
    "\n",
    "But hyperparameter tuning introduces a thrid set, a validation set.\n",
    "\n",
    "Now the process becomes, train a model on the training data, (try to) improve its hyperparameters on the validation set and evaluate it on the test set.\n",
    "\n",
    "If our starting dataset contained 100 different patient records labels indicating who had heart disease and who didn't and we wanted to build a machine learning model to predict who had heart disease and who didn't\n",
    "\n",
    "\n",
    "Since we know we're using a RandomForestClassifier and we know the hyperparameters we want to adjust, let's see what it looks like.\n",
    "\n",
    "First, let's remind ourselves of the base parameters.\n",
    "\n",
    "**Let's make 3 sets, training, validation and test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# base line parameters\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we're going to adjust:\n",
    "\n",
    "* max_depth\n",
    "* max_features\n",
    "* min_samples_leaf\n",
    "* min_samples_split\n",
    "* n_estimators\n",
    "\n",
    "We'll use the same code as before, except this time we'll create a training, validation and test split.\n",
    "\n",
    "With the training set containing 70% of the data and the validation and test sets each containing 15%.\n",
    "\n",
    "Let's get some baseline results, then we'll tune the model.\n",
    "\n",
    "And since we're going to be evaluating a few models, let's make an evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_preds):\n",
    "    \"\"\"\n",
    "    Performs evaluation comparison on y_true labels vs. y_pred labels\n",
    "    on a classification.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_preds)\n",
    "    precision = precision_score(y_true, y_preds)\n",
    "    recall = recall_score(y_true, y_preds)\n",
    "    f1 = f1_score(y_true, y_preds)\n",
    "    metric_dict = {\"accuracy\": round(accuracy, 2),\n",
    "                   \"precision\": round(precision, 2),\n",
    "                   \"recall\": round(recall, 2),\n",
    "                   \"f1\": round(f1, 2)}\n",
    "    print(f\"Acc: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 score: {f1:.2f}\")\n",
    "    \n",
    "    return metric_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 80.00%\n",
      "Precision: 0.77\n",
      "Recall: 0.92\n",
      "F1 score: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8, 'precision': 0.77, 'recall': 0.92, 'f1': 0.84}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle the data\n",
    "heart_disease_shuffled = heart_disease.sample(frac=1)\n",
    "\n",
    "# Split into X & y\n",
    "X = heart_disease_shuffled.drop(\"target\", axis=1)\n",
    "y = heart_disease_shuffled[\"target\"]\n",
    "\n",
    "# Split the data into train, validation & test sets\n",
    "train_split = round(0.7 * len(heart_disease_shuffled)) # 70% of data\n",
    "valid_split = round(train_split + 0.15 * len(heart_disease_shuffled)) # 15% of data\n",
    "X_train, y_train = X[:train_split], y[:train_split]\n",
    "X_valid, y_valid = X[train_split:valid_split], y[train_split:valid_split]\n",
    "X_test, y_test = X[valid_split:], y[:valid_split]\n",
    "\n",
    "#len(X_train), len(X_valid), len(X_test)\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make baseline predictions\n",
    "y_preds = clf.predict(X_valid)\n",
    "\n",
    "# Evaluate the classifier on validation set\n",
    "baseline_metrics = evaluate_preds(y_valid, y_preds)\n",
    "baseline_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 'warn',\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful, now let's try and improve the results.\n",
    "\n",
    "We'll change 1 of the hyperparameters, n_estimators to 100 and see if it improves on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 82.22%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n",
      "F1 score: 0.84\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# Create a second classifier with different hyperparameters\n",
    "clf_2 = RandomForestClassifier(n_estimators=100)\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with different hyperparameters\n",
    "y_preds_2 = clf_2.predict(X_valid)\n",
    "\n",
    "# Evalute the 2nd classsifier\n",
    "clf_2_metrics = evaluate_preds(y_valid, y_preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about we try another parameter?\n",
    "\n",
    "Wait...\n",
    "\n",
    "This could take a while if all we're doing is building new models with new hyperparameters each time.\n",
    "\n",
    "Surely there's a better way?\n",
    "\n",
    "There is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  tuning hyperparameters 2\n",
    "## 5.2 Hyperparameter tuning with RandomizedSearchCV\n",
    "Scikit-Learn's RandomizedSearchCV allows us to randomly search across different hyperparameters to see which work best. It also stores details about the ones which work best!\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "First, we create a grid (dictionary) of hyperparameters we'd like to search over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "**additional important information**\n",
    "\n",
    "Where did these values come from?\n",
    "\n",
    "They're made up.\n",
    "\n",
    "Made up?\n",
    "\n",
    "Yes. Not completely pulled out of the air but after reading the Scikit-Learn documentation on Random Forest's you'll see some of these values have certain values which usually perform well and certain hyperparameters take strings rather than integers.\n",
    "\n",
    "Now we've got the grid setup, Scikit-Learn's RandomizedSearchCV will look at it, pick a random value from each, instantiate a model with those values and test each model.\n",
    "\n",
    "How many models will it test?\n",
    "\n",
    "As many as there are for each combination of hyperparameters to be tested. Let's add them up.\n",
    "\n",
    "max_depth has 4, max_features has 2, min_samples_leaf has 3, min_samples_split has 3, n_estimators has 5. That's 4x2x3x3x5 = 360 models!\n",
    "\n",
    "Or...\n",
    "\n",
    "We can set the n_iter parameter to limit the number of models RandomizedSearchCV tests.\n",
    "\n",
    "The best thing? The results we get will be cross-validated (hence the CV in RandomizedSearchCV) so we can use train_test_split().\n",
    "\n",
    "And since we're going over so many different models, we'll set n_jobs to -1 of RandomForestClassifier so Scikit-Learn takes advantage of all the cores (processors) on our computers.\n",
    "\n",
    "Let's see it in action.\n",
    "\n",
    "Note: Depending on n_iter (how many models you test), the different values in the hyperparameter grid, and the power of your computer, running the cell below may take a while.\n",
    "\n",
    "Note 2: Setting n_jobs=-1 seems to be breaking on some machines (for me at least, as of 8 December 2019). There seems to be an issue about it, being tracked on GitHub. For the timebeing, n_jobs=1 seems to be working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.8s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.8s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.8s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.8s\n",
      "[CV] n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=1200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=5, total=   0.8s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30 \n",
      "[CV]  n_estimators=100, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=30, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=2, min_samples_leaf=2, max_features=sqrt, max_depth=10, total=   0.2s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.1s\n",
      "[CV] n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20 \n",
      "[CV]  n_estimators=100, min_samples_split=6, min_samples_leaf=1, max_features=auto, max_depth=20, total=   0.1s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=1, max_features=sqrt, max_depth=5, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=10, min_samples_split=4, min_samples_leaf=2, max_features=auto, max_depth=10, total=   0.0s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.4s\n",
      "[CV] n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=500, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.3s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.2s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None \n",
      "[CV]  n_estimators=200, min_samples_split=6, min_samples_leaf=2, max_features=sqrt, max_depth=None, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10 \n",
      "[CV]  n_estimators=200, min_samples_split=4, min_samples_leaf=4, max_features=auto, max_depth=10, total=   0.1s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.6s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.6s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.8s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.8s\n",
      "[CV] n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20 \n",
      "[CV]  n_estimators=1000, min_samples_split=4, min_samples_leaf=2, max_features=sqrt, max_depth=20, total=   0.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:   12.2s finished\n",
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators='warn',\n",
       "                                                    n_jobs=1, oob_score...\n",
       "                                                    random_state=None,\n",
       "                                                    verbose=0,\n",
       "                                                    warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 4, 6],\n",
       "                                        'n_estimators': [10, 100, 200, 500,\n",
       "                                                         1000, 1200]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "grid = {'n_estimators':[10, 100, 200, 500, 1000, 1200],\n",
    "       'max_depth': [None, 5, 10, 20, 30],\n",
    "       'max_features': ['auto', 'sqrt'],\n",
    "       'min_samples_split': [2,4,6],\n",
    "       'min_samples_leaf': [1,2,4]}\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#split into X and y\n",
    "X = heart_disease_shuffled.drop('target', axis = 1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "# split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate RandomForestClassifier\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# setup RandomizedSearchCV\n",
    "rs_clf = RandomizedSearchCV(estimator=clf,\n",
    "                           param_distributions=grid,\n",
    "                           n_iter = 10, # numbers of model to try\n",
    "                           cv = 5,\n",
    "                           verbose = 2)\n",
    "\n",
    "# fit the RandomizedSearchCV version of clf\n",
    "rs_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When RandomizedSearchCV goes through n_iter combinations of of hyperparameter search space, it stores the best ones in the attribute best_params_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 6,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': None}"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# which combination from above got best reults\n",
    "rs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we call predict() on rs_clf (our RandomizedSearchCV version of our classifier), it'll use the best hyperparameters it found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 81.97%\n",
      "Precision: 0.77\n",
      "Recall: 0.86\n",
      "F1 score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# make predictions with the best hyperparameters\n",
    "rs_y_preds = rs_clf.predict(X_test)\n",
    "\n",
    "# evaluate the predictions\n",
    "rs_metrics = evaluate_preds(y_test, rs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tuning hyperparameter 3\n",
    "## 5.3 Hyperparameter tuning with GridSearchCV\n",
    "The main difference between GridSearchCV and RandomizedSearchCV is GridSearchCV searches across a grid of hyperparamters exhaustively, where as, RandomizedSearchCV searches across a grid of hyperparameters randomly (stopping after n_iter combinations).\n",
    "\n",
    "For example, let's see our grid of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [10, 100, 200, 500, 1000, 1200],\n",
       " 'max_depth': [None, 5, 10, 20, 30],\n",
       " 'max_features': ['auto', 'sqrt'],\n",
       " 'min_samples_split': [2, 4, 6],\n",
       " 'min_samples_leaf': [1, 2, 4]}"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomizedSearchCV try n_iter combinations of different values. Where as, GridSearchCV will try every single possible combination.\n",
    "\n",
    "And if you remember from before when we did the calculation: max_depth has 4, max_features has 2, min_samples_leaf has 3, min_samples_split has 3, n_estimators has 5.\n",
    "\n",
    "That's 4x2x3x3x5 = 360 models!\n",
    "\n",
    "This could take a long time depending on the power of the computer you're using, the amount of data you have and the complexity of the hyperparamters (usually higher values means a more complex model).\n",
    "\n",
    "In our case, the data we're using is relatively small (only ~300 samples).\n",
    "\n",
    "Since we've already tried to find some ideal hyperparameters using RandomizedSearchCV, we'll create another hyperparameter grid based on the best_params_ of rs_clf* with less options and then try to use GridSearchCV to find a more ideal set.\n",
    "\n",
    "**Note**: Based on the best_params_ of rs_clf implies the next set of hyperparameters we'll try are roughly in the same range of the best set found by RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6*5*2*3*3*5 #(last 5 is cv, cross validated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another hyperparameter grid similar to rs_clf.best_params_\n",
    "grid_2 = {'n_estimators': [100, 200, 500],\n",
    "         'max_depth': [None],\n",
    "         'max_features': ['auto', 'sqrt'],\n",
    "         'min_samples_split': [6],\n",
    "         'min_samples_leaf': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3*1*2*1*2*5 # 5 is cv, cross vaidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=auto, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=100, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.1s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=200, total=   0.2s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.4s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n",
      "[CV] max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500 \n",
      "[CV]  max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=6, n_estimators=500, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:   11.6s finished\n",
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "#split into X and y\n",
    "X = heart_disease_shuffled.drop('target', axis = 1)\n",
    "y = heart_disease_shuffled['target']\n",
    "\n",
    "# split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# instantiate RandomForestClassifier\n",
    "# Set n_jobs to -1 to use all cores (NOTE: n_jobs=-1 is broken as of 8 Dec 2019, using n_jobs=1 works)\n",
    "clf = RandomForestClassifier(n_jobs=1)\n",
    "\n",
    "# setup GridSearchCV\n",
    "gs_clf = GridSearchCV(estimator=clf,\n",
    "                            param_grid=grid_2,\n",
    "                          cv = 5,\n",
    "                          verbose = 2)\n",
    "\n",
    "# fit the GridSearchCV version of clf\n",
    "gs_clf.fit(X_train, y_train);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 6,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the best hyperparameters found with GridSearchCV\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And by default when we call the predict() function on gs_clf, it'll use the best hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 78.69%\n",
      "Precision: 0.74\n",
      "Recall: 0.82\n",
      "F1 score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Max predictions with the GridSearchCV classifier\n",
    "gs_y_preds = gs_clf.predict(X_test)\n",
    "\n",
    "# evaluate the predictions\n",
    "gs_metrics = evaluate_preds(y_test, gs_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a DataFrame to compare the different metrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "compare_metrics = pd.DataFrame({\"baseline\": baseline_metrics,\n",
    "                                \"clf_2\": clf_2_metrics,\n",
    "                                \"random search\": rs_metrics,\n",
    "                                \"grid search\": gs_metrics})\n",
    "\n",
    "compare_metrics.plot.bar(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a hyperparameter tuning sense, there may be a better set we could find through more extensive searching with RandomizedSearchCV and GridSearchCV but it's likely these improvements will be marginal.\n",
    "\n",
    "A few next ideas you could try:\n",
    "\n",
    "* Collecting more data - Based on the results our models are getting now, it seems like they're finding some patterns. Collecting more data may improve a models ability to find patterns. However, your ability to do this will largely depend on the project you're working on.\n",
    "\n",
    "Since machine learning is part engineering, part science, these kind of experiments are common place in any machine learning project.\n",
    "\n",
    "Now you've got a somewhat tuned Random Forest model, the next thing you might want to do is export it and save it so you could share it with your team or use it in an application without having to retrain it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. saving and loading trained machine learning model\n",
    "Two ways to save and load machine learning models:\n",
    "\n",
    "1. With Python's pickle module\n",
    "2. With the joblib module\n",
    "\n",
    "**Pickle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving and loadel model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. putting it all together \n",
    "**Revisit the pipeline one more time, knowing what we know now**\n",
    "\n",
    "We've covered a lot. And so far, it seems to be all over the place, which it is. But not to worry, machine learning projects often start out like this. A whole bunch of experimenting and code all over the place at the start and then once you've found something which works, the refinement process begins.\n",
    "\n",
    "What would this refinement process look like?\n",
    "\n",
    "We'll use the car sales regression problem (predicting the sale price of cars) as an example.\n",
    "\n",
    "To tidy things up, we'll be using Scikit-Learn's Pipeline class. You can imagine Pipeline as being a way to string a number of different Scikit-Learn processes together.\n",
    "\n",
    "**7.1 Creating a regression Pipeline**\n",
    "\n",
    "You might recall when, way back in Section 2: Getting Data Ready, we dealt with the car sales data, to build a regression model on it, we had to encode the categorical features into numbers and fill the missing data.\n",
    "\n",
    "The code we used worked, but it was a bit all over the place. Good news is, Pipeline can help us clean it up.\n",
    "\n",
    "Let's remind ourselves what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Black</td>\n",
       "      <td>35820.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32042.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>White</td>\n",
       "      <td>155144.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5716.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>66604.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31570.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>215883.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4001.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Blue</td>\n",
       "      <td>248360.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12732.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors    Price\n",
       "0     Honda  White        35431.0    4.0  15323.0\n",
       "1       BMW   Blue       192714.0    5.0  19943.0\n",
       "2     Honda  White        84714.0    4.0  28343.0\n",
       "3    Toyota  White       154365.0    4.0  13434.0\n",
       "4    Nissan   Blue       181577.0    3.0  14043.0\n",
       "..      ...    ...            ...    ...      ...\n",
       "995  Toyota  Black        35820.0    4.0  32042.0\n",
       "996     NaN  White       155144.0    3.0   5716.0\n",
       "997  Nissan   Blue        66604.0    4.0  31570.0\n",
       "998   Honda  White       215883.0    4.0   4001.0\n",
       "999  Toyota   Blue       248360.0    4.0  12732.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              object\n",
       "Colour            object\n",
       "Odometer (KM)    float64\n",
       "Doors            float64\n",
       "Price            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             49\n",
       "Colour           50\n",
       "Odometer (KM)    50\n",
       "Doors            50\n",
       "Price            50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's 1000 rows, three features are categorical (Make, Colour, Doors), the other two are numerical (Odometer (KM), Price) and there's 249 missing values.\n",
    "\n",
    "We're going to have to turn the categorical features into numbers and fill the missing values before we can fit a model.\n",
    "\n",
    "We'll build a Pipeline() to do so.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "Pipeline()'s main input is steps which is a list ([(step_name, action_to_take)]) of the step name, plus the action you'd like it to perform. \n",
    "\n",
    "In our case, you could think of the steps as: steps we want to do (all in one cell)\n",
    "\n",
    "1. Fill missing data\n",
    "2. Convert data to numbers\n",
    "3. Build a model on the data\n",
    "\n",
    "Let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vishweshjoshi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1821575815702311"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting data ready\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Modelling\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# setup random seed\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "# import data and drop rows with missing labels. dropping rows with missing price\n",
    "data = pd.read_csv('car-sales-extended-missing-data.csv')\n",
    "data.dropna(subset=['Price'], inplace = True)\n",
    "\n",
    "# define different features and transformer pipeline\n",
    "categorical_features = ['Make', 'Colour']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('OneHot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "door_feature = ['Doors']\n",
    "door_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=4))\n",
    "])\n",
    "\n",
    "numeric_feature = ['Odometer (KM)']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "# setup preprocessing steps (fill missing values, then convert to numbers)\n",
    "preprocessor = ColumnTransformer(\n",
    "                    transformers=[\n",
    "                        ('cat', categorical_transformer, categorical_features),\n",
    "                        ('door', door_transformer, door_feature),\n",
    "                        ('num', numeric_transformer, numeric_feature)\n",
    "                    ])\n",
    "\n",
    "# create a preprocessing and modelling pipeline\n",
    "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                       ('model', RandomForestRegressor())])\n",
    "\n",
    "# split data\n",
    "X = data.drop('Price', axis = 1)\n",
    "y = data['Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "# fit and score the model\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we've done is combine a series of data preprocessing steps (filling missing values, encoding numerical values) as well as a model into a Pipeline().\n",
    "\n",
    "Doing so not only cleans up the code, it ensures the same steps are taken every time the code is run rather than having multiple different processing steps happening in different stages.\n",
    "\n",
    "It's also possible to GridSearchCV or RandomizedSearchCV with a Pipeline.\n",
    "\n",
    "The main difference is when creating a hyperparameter grid, you have to add a prefix to each hyperparameter.\n",
    "\n",
    "The prefix is the name of the Pipeline step you'd like to alter, followed by two underscores.\n",
    "\n",
    "For example, to adjust n_estimators of \"model\" in the Pipeline, you'd use: \"model__n_estimators\".\n",
    "\n",
    "Let's see it.\n",
    "\n",
    "# 137 putting it all together 2\n",
    "It's also possible to use GridSearchCV or RandomizedSesrchCV with our Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.4s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.5s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.6s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.3s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=None, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   1.2s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.9s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=2, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=mean, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=100, preprocessor__num__imputer__strategy=median, total=   0.1s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=mean, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n",
      "[CV] model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median \n",
      "[CV]  model__max_depth=5, model__max_features=auto, model__min_samples_split=4, model__n_estimators=1000, preprocessor__num__imputer__strategy=median, total=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   47.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('preprocessor',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('cat',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('imputer',\n",
       "                                                                                          SimpleImputer(add_indicator=False,\n",
       "                                                                                                        copy=True,\n",
       "                                                                                                        fill_value='missing',\n",
       "                                                                                                        missing_values=nan,\n",
       "                                                                                                        strategy=...\n",
       "                                                              random_state=None,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [None, 5],\n",
       "                         'model__max_features': ['auto'],\n",
       "                         'model__min_samples_split': [2, 4],\n",
       "                         'model__n_estimators': [100, 1000],\n",
       "                         'preprocessor__num__imputer__strategy': ['mean',\n",
       "                                                                  'median']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=2)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV with our regression Pipeline # hyperparameters with gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe_grid = {\n",
    "    \"preprocessor__num__imputer__strategy\": [\"mean\", \"median\"],\n",
    "    \"model__n_estimators\": [100, 1000],\n",
    "    \"model__max_depth\": [None, 5],\n",
    "    \"model__max_features\": [\"auto\"],\n",
    "    \"model__min_samples_split\": [2, 4]    \n",
    "}\n",
    "\n",
    "gs_model = GridSearchCV(model, pipe_grid, cv=5, verbose=2)\n",
    "gs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3337859800130589"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beautiful! Using GridSearchCV we see a nice boost in our models score. And the best thing is, because it's all in a Pipeline, we could easily replicate these results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0. An end-to-end Scikit-Learn workflow',\n",
       " '1. Getting the data ready',\n",
       " '2. Choose the right estimator/algorithm for our problems',\n",
       " '3. Fit the model/algorithm and use it to make predictions on our data',\n",
       " '4. Evaluating a model',\n",
       " '5. Improve a model',\n",
       " '6. Save and load a trained model',\n",
       " '7. Putting it all together!']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "what_were_covering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
